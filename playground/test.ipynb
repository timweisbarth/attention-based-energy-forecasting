{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\n"
     ]
    }
   ],
   "source": [
    "test = [1,2,3]\n",
    "print(test[-1:])\n",
    "import sys\n",
    "sys.path.append(\"./../utils/\")\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "#Modules of src folder\n",
    "import preproc as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'preproc' has no attribute 'load_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mworkalendar\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meurope\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Germany\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_data\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./../data/ts_60_sindex_DE_3f.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m df \u001b[38;5;241m=\u001b[39m pp\u001b[38;5;241m.\u001b[39mpreprocess(df)\n\u001b[1;32m      9\u001b[0m df \u001b[38;5;241m=\u001b[39m df[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDE_load_actual_entsoe_transparency\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mday\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m24\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m92\u001b[39m:\u001b[38;5;241m24\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m98\u001b[39m]\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'preproc' has no attribute 'load_data'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import date\n",
    "import holidays\n",
    "from workalendar.europe import Germany\n",
    "import numpy as np\n",
    "\n",
    "df = pp.load_data(\"./../data/ts_60_sindex_DE_3f.csv\")\n",
    "df = pp.preprocess(df)\n",
    "df = df[[\"DE_load_actual_entsoe_transparency\", \"year\", \"day\"]].iloc[24*92:24*98]\n",
    "\n",
    "years = range(2015,2021,1)\n",
    "holidays_GER = [holiday for holiday in holidays.Germany(years=years)]\n",
    "df_dates = pd.DataFrame(df.index.date)\n",
    "print(holidays_GER)\n",
    "df[\"isholiday\"] = df_dates.isin(holidays_GER).values.astype(int)\n",
    "df_dayofweek = pd.DataFrame(df.index.dayofweek)\n",
    "df[\"isSunday\"] = df_dayofweek.isin([6]).values.astype(int)\n",
    "df[\"isSaturday\"] = df_dayofweek.isin([5]).values.astype(int)\n",
    "df.head(30)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "('DE_load_actual_entsoe_transparency', 'day')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/thesis/lib/python3.11/site-packages/pandas/core/indexes/base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3789\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3790\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3791\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: ('DE_load_actual_entsoe_transparency', 'day')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/timw/Documents/University/thesis/Tutorials/test.ipynb Cell 3\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/timw/Documents/University/thesis/Tutorials/test.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m df \u001b[39m=\u001b[39m pp\u001b[39m.\u001b[39mload_data(\u001b[39m\"\u001b[39m\u001b[39m./../data/ts_60_sindex_DE_3f.csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/timw/Documents/University/thesis/Tutorials/test.ipynb#W2sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m df \u001b[39m=\u001b[39m pp\u001b[39m.\u001b[39mpreprocess(df)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/timw/Documents/University/thesis/Tutorials/test.ipynb#W2sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m df \u001b[39m=\u001b[39m df[\u001b[39m\"\u001b[39;49m\u001b[39mDE_load_actual_entsoe_transparency\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mday\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39miloc[\u001b[39m0\u001b[39m:\u001b[39m1000\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/timw/Documents/University/thesis/Tutorials/test.ipynb#W2sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# Generate a list of holidays for the given years\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/timw/Documents/University/thesis/Tutorials/test.ipynb#W2sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m years \u001b[39m=\u001b[39m \u001b[39mrange\u001b[39m(\u001b[39m2015\u001b[39m, \u001b[39m2021\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/thesis/lib/python3.11/site-packages/pandas/core/frame.py:3896\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3894\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3895\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3896\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3897\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3898\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/thesis/lib/python3.11/site-packages/pandas/core/indexes/base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3792\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(casted_key, \u001b[39mslice\u001b[39m) \u001b[39mor\u001b[39;00m (\n\u001b[1;32m   3793\u001b[0m         \u001b[39misinstance\u001b[39m(casted_key, abc\u001b[39m.\u001b[39mIterable)\n\u001b[1;32m   3794\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, \u001b[39mslice\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m casted_key)\n\u001b[1;32m   3795\u001b[0m     ):\n\u001b[1;32m   3796\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3797\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3798\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3799\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3800\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: ('DE_load_actual_entsoe_transparency', 'day')"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import holidays\n",
    "\n",
    "# Assuming your 'pp.load_data' and 'pp.preprocess' functions are defined elsewhere and working.\n",
    "df = pp.load_data(\"./../data/ts_60_sindex_DE_3f.csv\")\n",
    "df = pp.preprocess(df)\n",
    "df = df[\"DE_load_actual_entsoe_transparency\",\"day\"].iloc[0:1000]\n",
    "\n",
    "# Generate a list of holidays for the given years\n",
    "years = range(2015, 2021)\n",
    "holidays_GER = [date for year in years for date in holidays.Germany(years=year)]\n",
    "\n",
    "# Ensure that your dataframe index is of type datetime\n",
    "df.index = pd.to_datetime(df.index)\n",
    "\n",
    "series = pd.DataFrame(df.index.date)\n",
    "\n",
    "# Create the one-hot encoded column\n",
    "df['is_holiday'] = series.isin(holidays_GER).astype(int)\n",
    "\n",
    "print(df.head())\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   10   20\n",
      "10   20   30\n"
     ]
    }
   ],
   "source": [
    "w = 10\n",
    "h = 10\n",
    "length = 33\n",
    "seq_length = w + h\n",
    "\n",
    "for i in range(0,length-seq_length, w):\n",
    "    print(i, \" \", i+w, \" \", i+w+h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   10   20\n",
      "10   20   30\n"
     ]
    }
   ],
   "source": [
    "w = 10\n",
    "h = 10\n",
    "length = 40\n",
    "seq_length = w + h\n",
    "\n",
    "for i in range(0,length-seq_length, w):\n",
    "    print(i, \" \", i+w, \" \", i+w+h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   5   15\n",
      "5   10   20\n",
      "10   15   25\n",
      "15   20   30\n",
      "20   25   35\n"
     ]
    }
   ],
   "source": [
    "w = 5\n",
    "h = 10\n",
    "length = 40\n",
    "seq_length = w + h\n",
    "\n",
    "for i in range(0,length-seq_length, w):\n",
    "    print(i, \" \", i+w, \" \", i+w+h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "1 2\n",
      "20\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "def pipeline(uno, dos):\n",
    "    print(uno)\n",
    "    print(dos)\n",
    "\n",
    "dic = {\"dos\":10, \"uno\":20}\n",
    "print(dic[\"dos\"])\n",
    "arr = [1,2]\n",
    "print(*arr)\n",
    "pipeline(**dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uno': 20, 'dic2': {'hello': 2}}\n"
     ]
    }
   ],
   "source": [
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "dic = dotdict(dic)\n",
    "dic.dos\n",
    "dic.dos = 20\n",
    "del(dic.dos)\n",
    "dic\n",
    "\n",
    "dic.dic2 = dotdict({})\n",
    "dic.dic2.hello = 2\n",
    "print(dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What does error metric do if target dimensionality is larger than 1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.528200816389788\n",
      "9.382497002397603\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "y_true = [[0.5, 25],[-1, 10],[2, -6], [9,1]]\n",
    "y_pred = [[0, 2],[-1, 2],[8, -5], [2,6]]\n",
    "length = len(y_true)\n",
    "print(mean_squared_error(y_true, y_pred, squared=False))\n",
    "print(mean_squared_error(y_true, y_pred) **0.5)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.50e-01 5.29e+02]\n",
      " [0.00e+00 6.40e+01]\n",
      " [3.60e+01 1.00e+00]\n",
      " [4.90e+01 2.50e+01]]\n",
      "[ 4.61654633 12.4398553 ]\n",
      "8.528200816389788\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "arr = np.array([((true[0] - pred[0])**2, (true[1] - pred[1])**2) for true, pred in zip(y_true, y_pred)])\n",
    "print(arr)\n",
    "arr = (1/ length* np.sum(arr, axis=0))**0.5\n",
    "print(arr)\n",
    "arr = 0.5 * np.sum(arr, axis=-1)\n",
    "print(arr)\n",
    "\n",
    "# ---> Result: sklearn first computes rmse for every dimension and then averages. This is how the mulit dimensional rmse should be calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'copy': True, 'with_mean': True, 'with_std': True}\n",
      "[[-1.22474487]\n",
      " [ 0.        ]\n",
      " [ 1.22474487]]\n",
      "[[1.         1.18350342 1.        ]\n",
      " [2.         2.         2.        ]\n",
      " [3.         3.         3.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "scaler = StandardScaler()\n",
    "arr = np.array([[1],[2],[3]])\n",
    "arr_scaled = scaler.fit_transform(arr)\n",
    "print(scaler.get_params())\n",
    "print(arr_scaled)\n",
    "arr_scaled2= np.repeat(arr_scaled, 3, axis=1)\n",
    "arr_scaled2[0,1] = -1\n",
    "arr_rescaled = scaler.inverse_transform(arr_scaled2)\n",
    "print(arr_rescaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#import pandas as pd\n",
    "#df = pd.DataFrame({\"A\":[1,2,3], \"B\":[4,5,6]})\n",
    "\n",
    "\n",
    "for i in range(0,2,2):\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3272000000000002"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1.51 * 24 + 1.0 * 18 + 15 * 1.7 + 6 * 1.3 + 9 * 1.0 + 3 * 1.0) / (24+18+30+3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0412, 0.5561, 0.3932, 0.9025],\n",
       "         [0.0365, 0.4193, 0.0926, 0.7166],\n",
       "         [0.2153, 0.0146, 0.6820, 0.7265],\n",
       "         [0.9382, 0.8759, 0.3992, 0.2185],\n",
       "         [0.7779, 0.8717, 0.2100, 0.0883],\n",
       "         [0.0333, 0.6609, 0.8918, 0.3295]],\n",
       "\n",
       "        [[0.5160, 0.4311, 0.8420, 0.7996],\n",
       "         [0.0198, 0.1928, 0.5428, 0.6769],\n",
       "         [0.6492, 0.9890, 0.0107, 0.3309],\n",
       "         [0.5175, 0.2173, 0.5726, 0.8755],\n",
       "         [0.8080, 0.5379, 0.7746, 0.5921],\n",
       "         [0.8261, 0.3748, 0.3618, 0.1849]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.rand((2,6,4))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.0412, 0.5561],\n",
       "          [0.3932, 0.9025]],\n",
       "\n",
       "         [[0.0365, 0.4193],\n",
       "          [0.0926, 0.7166]],\n",
       "\n",
       "         [[0.2153, 0.0146],\n",
       "          [0.6820, 0.7265]],\n",
       "\n",
       "         [[0.9382, 0.8759],\n",
       "          [0.3992, 0.2185]],\n",
       "\n",
       "         [[0.7779, 0.8717],\n",
       "          [0.2100, 0.0883]],\n",
       "\n",
       "         [[0.0333, 0.6609],\n",
       "          [0.8918, 0.3295]]],\n",
       "\n",
       "\n",
       "        [[[0.5160, 0.4311],\n",
       "          [0.8420, 0.7996]],\n",
       "\n",
       "         [[0.0198, 0.1928],\n",
       "          [0.5428, 0.6769]],\n",
       "\n",
       "         [[0.6492, 0.9890],\n",
       "          [0.0107, 0.3309]],\n",
       "\n",
       "         [[0.5175, 0.2173],\n",
       "          [0.5726, 0.8755]],\n",
       "\n",
       "         [[0.8080, 0.5379],\n",
       "          [0.7746, 0.5921]],\n",
       "\n",
       "         [[0.8261, 0.3748],\n",
       "          [0.3618, 0.1849]]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.view(2,6,2,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>val1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-23 23:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-02-23 23:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-03-24 23:00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-09-23 23:00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-23 23:00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-01-13 23:00</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021-01-23 23:00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021-02-23 23:00</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2022-01-23 23:00</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022-02-23 23:00</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2023-01-23 23:00</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2023-02-23 23:00</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                date  val1\n",
       "0   2019-01-23 23:00     1\n",
       "1   2019-02-23 23:00     2\n",
       "2   2020-03-24 23:00     3\n",
       "3   2020-09-23 23:00     4\n",
       "4   2020-01-23 23:00     5\n",
       "5   2021-01-13 23:00     6\n",
       "6   2021-01-23 23:00     7\n",
       "7   2021-02-23 23:00     8\n",
       "8   2022-01-23 23:00     9\n",
       "9   2022-02-23 23:00    10\n",
       "10  2023-01-23 23:00    11\n",
       "11  2023-02-23 23:00    12"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw = pd.DataFrame(\n",
    "    {\"date\": [\"2019-01-23 23:00\", \"2019-02-23 23:00\", \"2020-03-24 23:00\", \"2020-09-23 23:00\", \"2020-01-23 23:00\", \"2021-01-13 23:00\", \"2021-01-23 23:00\", \"2021-02-23 23:00\", \"2022-01-23 23:00\", \"2022-02-23 23:00\", \"2023-01-23 23:00\", \"2023-02-23 23:00\"],\n",
    "    \"val1\": [1,2,3,4,5,6,7,8,9,10,11,12]}\n",
    ")\n",
    "df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>val1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-23 23:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-02-23 23:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-03-24 23:00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-09-23 23:00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-23 23:00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-01-13 23:00</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021-01-23 23:00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021-02-23 23:00</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2022-01-23 23:00</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022-02-23 23:00</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2023-01-23 23:00</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2023-02-23 23:00</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                date  val1\n",
       "0   2019-01-23 23:00     1\n",
       "1   2019-02-23 23:00     2\n",
       "2   2020-03-24 23:00     3\n",
       "3   2020-09-23 23:00     4\n",
       "4   2020-01-23 23:00     5\n",
       "5   2021-01-13 23:00     6\n",
       "6   2021-01-23 23:00     7\n",
       "7   2021-02-23 23:00     8\n",
       "8   2022-01-23 23:00     9\n",
       "9   2022-02-23 23:00    10\n",
       "10  2023-01-23 23:00    11\n",
       "11  2023-02-23 23:00    12"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw = df_raw.rename(columns={\"asdf\": \"asd\"})\n",
    "df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "df_raw[\"date\"] = pd.to_datetime(df_raw[\"date\"])\n",
    "mask_train = df_raw['date'].dt.year < 2021\n",
    "# Index + 1 is the number of training elements\n",
    "num_train = df_raw[mask_train].last_valid_index() + 1 \n",
    "mask_val = df_raw['date'].dt.year == 2021\n",
    "# Substract the indexes for the number of validation elements\n",
    "num_val = df_raw[mask_val].last_valid_index() - (num_train - 1) \n",
    "num_test = len(df_raw) - num_train - num_val\n",
    "\n",
    "print(num_train)\n",
    "print(num_val)\n",
    "print(num_test)\n",
    "\n",
    "assert num_test > 0\n",
    "assert num_train > num_test > num_val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>val1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-23 23:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-02-23 23:00:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-03-24 23:00:00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-09-23 23:00:00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-23 23:00:00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-01-13 23:00:00</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021-01-23 23:00:00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021-02-23 23:00:00</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2022-01-23 23:00:00</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022-02-23 23:00:00</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2023-01-23 23:00:00</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2023-02-23 23:00:00</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date  val1\n",
       "0  2019-01-23 23:00:00     1\n",
       "1  2019-02-23 23:00:00     2\n",
       "2  2020-03-24 23:00:00     3\n",
       "3  2020-09-23 23:00:00     4\n",
       "4  2020-01-23 23:00:00     5\n",
       "5  2021-01-13 23:00:00     6\n",
       "6  2021-01-23 23:00:00     7\n",
       "7  2021-02-23 23:00:00     8\n",
       "8  2022-01-23 23:00:00     9\n",
       "9  2022-02-23 23:00:00    10\n",
       "10 2023-01-23 23:00:00    11\n",
       "11 2023-02-23 23:00:00    12"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(df_raw.date.dt.month, df_raw.date.apply(lambda row: row.month))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3, 4])\n",
    "print(x.shape)\n",
    "x.unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  2.,  4.,  6.,  8., 10.])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(0, 12, 2).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00000000e+00, -2.44929360e-16, -8.30894028e-02,  1.68139005e-02,\n",
       "       -6.63218974e-02,  3.36230472e-02])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sin([0,2*np.pi, 62/10, 63/10, 125/10, 126/10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.sin(np.arange(0,10000000))\n",
    "\n",
    "len(np.unique(x)) == len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model              Transformer 1          Transformer 2         \n",
      "Metric                  Metric 1 Metric 2      Metric 1 Metric 2\n",
      "Target   Horizon                                                \n",
      "Target 1 Horizon 1             -        -             -        -\n",
      "         Horizon 2             -        -             -        -\n",
      "Target 2 Horizon 1             -        -             -        -\n",
      "         Horizon 2             -        -             -        -\n",
      "Model              Transformer 1          Transformer 2         \n",
      "Metric                  Metric 1 Metric 2      Metric 1 Metric 2\n",
      "Target   Horizon                                                \n",
      "Target 1 Horizon 1             -        -             -        -\n",
      "         Horizon 2             -        -             -        2\n",
      "Target 2 Horizon 1             -        -             -        -\n",
      "         Horizon 2             -        -             -        -\n",
      "\\begin{tabular}{llllll}\n",
      "\\toprule\n",
      " & Model & \\multicolumn{2}{r}{Transformer 1} & \\multicolumn{2}{r}{Transformer 2} \\\\\n",
      " & Metric & Metric 1 & Metric 2 & Metric 1 & Metric 2 \\\\\n",
      "Target & Horizon &  &  &  &  \\\\\n",
      "\\midrule\n",
      "\\multirow[t]{2}{*}{Target 1} & Horizon 1 & - & - & - & - \\\\\n",
      " & Horizon 2 & - & - & - & 2 \\\\\n",
      "\\cline{1-6}\n",
      "\\multirow[t]{2}{*}{Target 2} & Horizon 1 & - & - & - & - \\\\\n",
      " & Horizon 2 & - & - & - & - \\\\\n",
      "\\cline{1-6}\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the levels for the MultiIndex of the rows\n",
    "targets = ['Target 1', 'Target 2']  # Customize your targets\n",
    "horizons = ['Horizon 1', 'Horizon 2']  # Customize your horizons\n",
    "\n",
    "# Define the levels for the MultiIndex of the columns\n",
    "transformers = ['Transformer 1', 'Transformer 2']  # Customize your transformers\n",
    "metrics = ['Metric 1', 'Metric 2']  # Customize your metrics\n",
    "\n",
    "# Create the MultiIndex for the rows\n",
    "row_index = pd.MultiIndex.from_product([targets, horizons], names=['Target', 'Horizon'])\n",
    "\n",
    "# Create the MultiIndex for the columns\n",
    "column_index = pd.MultiIndex.from_product([transformers, metrics], names=['Model', 'Metric'])\n",
    "\n",
    "# Initialize the DataFrame with MultiIndex for both rows and columns\n",
    "metrics_df = pd.DataFrame(index=row_index, columns=column_index).fillna('-')  # Fill with placeholder for clarity\n",
    "\n",
    "# Display the DataFrame\n",
    "print(metrics_df)\n",
    "\n",
    "# Access the specific entry\n",
    "metrics_df.loc[('Target 1', 'Horizon 2'), ('Transformer 2', 'Metric 2')] = 2\n",
    "\n",
    "print(metrics_df)\n",
    "\n",
    "\n",
    "# Convert the DataFrame to a LaTeX table\n",
    "latex_table = metrics_df.to_latex()\n",
    "\n",
    "# Print the LaTeX table string\n",
    "print(latex_table)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('hello', 1), ('hello2', 2)]\n"
     ]
    }
   ],
   "source": [
    "dic = {\n",
    "    \"hello\": 1,\n",
    "    \"hello2\": 2\n",
    "}\n",
    "print([item for item in dic.items()])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2019-01-23 23:00:00', '2019-02-23 23:00:00'], dtype='datetime64[ns]', freq=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_stamp = pd.DataFrame(\n",
    "    {\"date\": [\"2019-01-23 23:00\", \"2019-02-23 23:00\"]}\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_stamp['date'] = pd.to_datetime(df_stamp.date)\n",
    "pd.to_datetime(df_stamp['date'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 date  val1\n",
      "0 2019-01-23 23:00:00     1\n",
      "1 2019-02-23 23:00:00     1\n",
      "                 date\n",
      "0 2019-01-23 23:00:00\n",
      "1 2019-02-23 23:00:00\n"
     ]
    }
   ],
   "source": [
    "df_stamp2 = df_stamp.copy()\n",
    "\n",
    "df_stamp[\"val1\"] = 1\n",
    "\n",
    "print(df_stamp)\n",
    "print(df_stamp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3  4  5]\n",
      " [ 6  7  8  9 10]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Creating a pandas Index\n",
    "index = pd.Index([1, 2, 3, 4, 5])\n",
    "\n",
    "# Creating a numpy array\n",
    "array = np.array([6, 7, 8, 9, 10])\n",
    "\n",
    "# Attempt to stack them directly\n",
    "stacked_array = np.vstack((index, array))\n",
    "\n",
    "print(stacked_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0, 1, 2, 3],\n",
      "         [4, 5, 6, 7]]]) torch.Size([1, 2, 4])\n",
      "i1:  tensor([[0],\n",
      "        [1]]) torch.Size([2, 1])\n",
      "i2:  tensor([[0, 1, 2]]) torch.Size([1, 3])\n",
      "i3:  tensor([[1, 0, 1, 1],\n",
      "        [0, 1, 0, 1]])  torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.arange(0, 8, 1).view(1,2,4)\n",
    "print(x, x.shape)\n",
    "\n",
    "i1 = torch.arange(0, 2, 1).view(2,1)\n",
    "i2 = torch.arange(0, 3, 1).view(1,3)\n",
    "print(\"i1: \", i1, i1.shape)\n",
    "print(\"i2: \", i2, i2.shape)\n",
    "\n",
    "i3 = torch.randint(0, 2, (2,4))\n",
    "print(\"i3: \", i3,\"\", i3.shape)\n",
    "\n",
    "# (2,), (3,1) -> (3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for dimension 1 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m display(\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi2\u001b[49m\u001b[43m]\u001b[49m, x[i1, i2]\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      2\u001b[0m display(x[i3], x[i3]\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 2 is out of bounds for dimension 1 with size 2"
     ]
    }
   ],
   "source": [
    "display(x[i1, i2], x[i1, i2].shape)\n",
    "display(x[i3], x[i3].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([[[3, 2],\n",
       "         [7, 6]]]),\n",
       "indices=tensor([[[3, 2],\n",
       "         [3, 2]]]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.max(-1)[0].shape\n",
    "x.topk(2, sorted=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0, 1, 2, 3]]]])\n",
      "tensor([[[[0, 1, 2, 3],\n",
      "          [0, 1, 2, 3]],\n",
      "\n",
      "         [[0, 1, 2, 3],\n",
      "          [0, 1, 2, 3]],\n",
      "\n",
      "         [[0, 1, 2, 3],\n",
      "          [0, 1, 2, 3]]],\n",
      "\n",
      "\n",
      "        [[[0, 1, 2, 3],\n",
      "          [0, 1, 2, 3]],\n",
      "\n",
      "         [[0, 1, 2, 3],\n",
      "          [0, 1, 2, 3]],\n",
      "\n",
      "         [[0, 1, 2, 3],\n",
      "          [0, 1, 2, 3]]],\n",
      "\n",
      "\n",
      "        [[[0, 1, 2, 3],\n",
      "          [0, 1, 2, 3]],\n",
      "\n",
      "         [[0, 1, 2, 3],\n",
      "          [0, 1, 2, 3]],\n",
      "\n",
      "         [[0, 1, 2, 3],\n",
      "          [0, 1, 2, 3]]],\n",
      "\n",
      "\n",
      "        [[[0, 1, 2, 3],\n",
      "          [0, 1, 2, 3]],\n",
      "\n",
      "         [[0, 1, 2, 3],\n",
      "          [0, 1, 2, 3]],\n",
      "\n",
      "         [[0, 1, 2, 3],\n",
      "          [0, 1, 2, 3]]]])\n"
     ]
    }
   ],
   "source": [
    "length = 4\n",
    "print(torch.arange(length).unsqueeze(0).unsqueeze(0).unsqueeze(0))\n",
    "init_index = torch.arange(length).unsqueeze(0).unsqueeze(0).unsqueeze(0)\\\n",
    "            .repeat(4, 3, 2, 1)\n",
    "print(init_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 10, 2])\n",
      "torch.Size([32, 5, 1])\n",
      "torch.Size([10, 2])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 2 is not equal to len(dims) = 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 34\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(X\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, y)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Backward pass and optimize\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/thesis/lib/python3.11/site-packages/torchtsmixer/tsmixer.py:108\u001b[0m, in \u001b[0;36mTSMixer.forward\u001b[0;34m(self, x_hist)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x_hist: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m    100\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Forward pass of the TSMixer model.\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \n\u001b[1;32m    102\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m        torch.Tensor: The output tensor after processing by the model.\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 108\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmixer_layers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_hist\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m     x_temp \u001b[38;5;241m=\u001b[39m feature_to_time(x)\n\u001b[1;32m    111\u001b[0m     x_temp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemporal_projection(x_temp)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/thesis/lib/python3.11/site-packages/torchtsmixer/layers.py:316\u001b[0m, in \u001b[0;36mMixerLayer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Forward pass for the MixLayer module.\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \n\u001b[1;32m    310\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;124;03m        The output tensor after applying time and feature mixing operations.\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 316\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime_mixing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Apply time mixing first.\u001b[39;00m\n\u001b[1;32m    317\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_mixing(x)  \u001b[38;5;66;03m# Then apply feature mixing.\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/thesis/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/thesis/lib/python3.11/site-packages/torchtsmixer/layers.py:249\u001b[0m, in \u001b[0;36mTimeMixing.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m    240\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Applies the time mixing operations on the input tensor.\u001b[39;00m\n\u001b[1;32m    241\u001b[0m \n\u001b[1;32m    242\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;124;03m        The normalized output tensor after time mixing transformations.\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 249\u001b[0m     x_temp \u001b[38;5;241m=\u001b[39m \u001b[43mfeature_to_time\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Convert feature maps to time dimension. Assumes definition elsewhere.\u001b[39;00m\n\u001b[1;32m    252\u001b[0m     x_temp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation_fn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(x_temp))\n\u001b[1;32m    253\u001b[0m     x_temp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x_temp)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/thesis/lib/python3.11/site-packages/torchtsmixer/layers.py:392\u001b[0m, in \u001b[0;36mtime_to_feature\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtime_to_feature\u001b[39m(x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m    391\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Converts a time series tensor to a feature tensor.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 392\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 2 is not equal to len(dims) = 3"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchtsmixer import TSMixer\n",
    "\n",
    "# Model parameters\n",
    "sequence_length = 10\n",
    "prediction_length = 5\n",
    "input_channels = 2\n",
    "output_channels = 1\n",
    "\n",
    "# Create the TSMixer model\n",
    "model = TSMixer(sequence_length, prediction_length, input_channels, output_channels)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# Dummy dataset (replace with real data)\n",
    "# Assuming batch_size, seq_len, num_features format\n",
    "X_train = torch.randn(32, sequence_length, input_channels)\n",
    "print(X_train.shape)\n",
    "y_train = torch.randn(32, prediction_length, output_channels)\n",
    "print(y_train.shape)\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for X,y in zip(X_train, y_train):\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        print(X.shape)\n",
    "        # Forward pass\n",
    "        outputs = model(X)\n",
    "        loss = criterion(outputs, y)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "print(\"Training complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 5, 4])\n"
     ]
    }
   ],
   "source": [
    "from torchtsmixer import TSMixer\n",
    "import torch\n",
    "\n",
    "m = TSMixer(sequence_length=10, prediction_length=5, input_channels=2, output_channels=4)\n",
    "x = torch.randn(3, 10, 2)\n",
    "y = m(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 2]) torch.Size([5, 4])\n",
      "torch.Size([10, 2]) torch.Size([5, 4])\n",
      "torch.Size([10, 2]) torch.Size([5, 4])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, 10, 2)\n",
    "y = torch.randn(3, 5, 4)\n",
    "\n",
    "for x_i,y_i in zip(x,y):\n",
    "    print(x_i.shape, y_i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n"
     ]
    }
   ],
   "source": [
    "test = [1,2,3]\n",
    "print(sum(test)/len(test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,)\n",
      "(1,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Frequency'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "print(np.arange(10000).shape)\n",
    "print(np.array([1000000000]).shape)\n",
    "df = pd.DataFrame({\"A\": np.concatenate((np.arange(10000), np.array([1000000000])))})\n",
    "df.describe()\n",
    "df.plot.hist(bins=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
